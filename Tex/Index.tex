
    




    
\documentclass[11pt]{article}

    
    \usepackage[breakable]{tcolorbox}
    \tcbset{nobeforeafter} % prevents tcolorboxes being placing in paragraphs
    \usepackage{float}
    \floatplacement{figure}{H} % forces figures to be placed at the correct location
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{mathrsfs}
    

    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    \title{Index}
    
    
    
    
    
% Pygments definitions
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % For linebreaks inside Verbatim environment from package fancyvrb. 
    \makeatletter
        \newbox\Wrappedcontinuationbox 
        \newbox\Wrappedvisiblespacebox 
        \newcommand*\Wrappedvisiblespace {\textcolor{red}{\textvisiblespace}} 
        \newcommand*\Wrappedcontinuationsymbol {\textcolor{red}{\llap{\tiny$\m@th\hookrightarrow$}}} 
        \newcommand*\Wrappedcontinuationindent {3ex } 
        \newcommand*\Wrappedafterbreak {\kern\Wrappedcontinuationindent\copy\Wrappedcontinuationbox} 
        % Take advantage of the already applied Pygments mark-up to insert 
        % potential linebreaks for TeX processing. 
        %        {, <, #, %, $, ' and ": go to next line. 
        %        _, }, ^, &, >, - and ~: stay at end of broken line. 
        % Use of \textquotesingle for straight quote. 
        \newcommand*\Wrappedbreaksatspecials {% 
            \def\PYGZus{\discretionary{\char`\_}{\Wrappedafterbreak}{\char`\_}}% 
            \def\PYGZob{\discretionary{}{\Wrappedafterbreak\char`\{}{\char`\{}}% 
            \def\PYGZcb{\discretionary{\char`\}}{\Wrappedafterbreak}{\char`\}}}% 
            \def\PYGZca{\discretionary{\char`\^}{\Wrappedafterbreak}{\char`\^}}% 
            \def\PYGZam{\discretionary{\char`\&}{\Wrappedafterbreak}{\char`\&}}% 
            \def\PYGZlt{\discretionary{}{\Wrappedafterbreak\char`\<}{\char`\<}}% 
            \def\PYGZgt{\discretionary{\char`\>}{\Wrappedafterbreak}{\char`\>}}% 
            \def\PYGZsh{\discretionary{}{\Wrappedafterbreak\char`\#}{\char`\#}}% 
            \def\PYGZpc{\discretionary{}{\Wrappedafterbreak\char`\%}{\char`\%}}% 
            \def\PYGZdl{\discretionary{}{\Wrappedafterbreak\char`\$}{\char`\$}}% 
            \def\PYGZhy{\discretionary{\char`\-}{\Wrappedafterbreak}{\char`\-}}% 
            \def\PYGZsq{\discretionary{}{\Wrappedafterbreak\textquotesingle}{\textquotesingle}}% 
            \def\PYGZdq{\discretionary{}{\Wrappedafterbreak\char`\"}{\char`\"}}% 
            \def\PYGZti{\discretionary{\char`\~}{\Wrappedafterbreak}{\char`\~}}% 
        } 
        % Some characters . , ; ? ! / are not pygmentized. 
        % This macro makes them "active" and they will insert potential linebreaks 
        \newcommand*\Wrappedbreaksatpunct {% 
            \lccode`\~`\.\lowercase{\def~}{\discretionary{\hbox{\char`\.}}{\Wrappedafterbreak}{\hbox{\char`\.}}}% 
            \lccode`\~`\,\lowercase{\def~}{\discretionary{\hbox{\char`\,}}{\Wrappedafterbreak}{\hbox{\char`\,}}}% 
            \lccode`\~`\;\lowercase{\def~}{\discretionary{\hbox{\char`\;}}{\Wrappedafterbreak}{\hbox{\char`\;}}}% 
            \lccode`\~`\:\lowercase{\def~}{\discretionary{\hbox{\char`\:}}{\Wrappedafterbreak}{\hbox{\char`\:}}}% 
            \lccode`\~`\?\lowercase{\def~}{\discretionary{\hbox{\char`\?}}{\Wrappedafterbreak}{\hbox{\char`\?}}}% 
            \lccode`\~`\!\lowercase{\def~}{\discretionary{\hbox{\char`\!}}{\Wrappedafterbreak}{\hbox{\char`\!}}}% 
            \lccode`\~`\/\lowercase{\def~}{\discretionary{\hbox{\char`\/}}{\Wrappedafterbreak}{\hbox{\char`\/}}}% 
            \catcode`\.\active
            \catcode`\,\active 
            \catcode`\;\active
            \catcode`\:\active
            \catcode`\?\active
            \catcode`\!\active
            \catcode`\/\active 
            \lccode`\~`\~ 	
        }
    \makeatother

    \let\OriginalVerbatim=\Verbatim
    \makeatletter
    \renewcommand{\Verbatim}[1][1]{%
        %\parskip\z@skip
        \sbox\Wrappedcontinuationbox {\Wrappedcontinuationsymbol}%
        \sbox\Wrappedvisiblespacebox {\FV@SetupFont\Wrappedvisiblespace}%
        \def\FancyVerbFormatLine ##1{\hsize\linewidth
            \vtop{\raggedright\hyphenpenalty\z@\exhyphenpenalty\z@
                \doublehyphendemerits\z@\finalhyphendemerits\z@
                \strut ##1\strut}%
        }%
        % If the linebreak is at a space, the latter will be displayed as visible
        % space at end of first line, and a continuation symbol starts next line.
        % Stretch/shrink are however usually zero for typewriter font.
        \def\FV@Space {%
            \nobreak\hskip\z@ plus\fontdimen3\font minus\fontdimen4\font
            \discretionary{\copy\Wrappedvisiblespacebox}{\Wrappedafterbreak}
            {\kern\fontdimen2\font}%
        }%
        
        % Allow breaks at special characters using \PYG... macros.
        \Wrappedbreaksatspecials
        % Breaks at punctuation characters . , ; ? ! and / need catcode=\active 	
        \OriginalVerbatim[#1,codes*=\Wrappedbreaksatpunct]%
    }
    \makeatother

    % Exact colors from NB
    \definecolor{incolor}{HTML}{303F9F}
    \definecolor{outcolor}{HTML}{D84315}
    \definecolor{cellborder}{HTML}{CFCFCF}
    \definecolor{cellbackground}{HTML}{F7F7F7}
    
    % prompt
    \newcommand{\prompt}[4]{
        \llap{{\color{#2}[#3]: #4}}\vspace{-1.25em}
    }
    

    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \hypertarget{reinforcement-learning-using-openai-gym}{%
\section{Reinforcement Learning Using OpenAI
Gym}\label{reinforcement-learning-using-openai-gym}}

    \hypertarget{quick-introduction-to-rl-reinforcement-learning}{%
\subsection{Quick Introduction to RL (Reinforcement
Learning)}\label{quick-introduction-to-rl-reinforcement-learning}}

Reinforcement learning (RL) is an area of machine learning concerned
with how software agents ought to take actions in an environment so as
to maximize some notion of cumulative reward. Reinforcement learning is
one of three basic machine learning paradigms, alongside supervised
learning and unsupervised learning.

It differs from supervised learning in that labelled input/output pairs
need not be presented, and sub-optimal actions need not be explicitly
corrected. Instead the focus is finding a balance between exploration
(of uncharted territory) and exploitation (of current knowledge).

The environment is typically formulated as a Markov decision process
(MDP), as many reinforcement learning algorithms for this context
utilize dynamic programming techniques. The main difference between the
classical dynamic programming methods and reinforcement learning
algorithms is that the latter do not assume knowledge of an exact
mathematical model of the MDP and they target large MDPs where exact
methods become infeasible.

\textbf{source}: https://en.wikipedia.org/wiki/Reinforcement\_learning

    \hypertarget{experiments-with-openai-gym}{%
\subsection{Experiments with OpenAI
Gym}\label{experiments-with-openai-gym}}

Gym is a toolkit for developing and comparing reinforcement learning
algorithms. It makes no assumptions about the structure of your agent,
and is compatible with any numerical computation library, such as
TensorFlow or Theano.

The gym library is a collection of test problems --- environments ---
that you can use to work out your reinforcement learning algorithms.
These environments have a shared interface, allowing you to write
general algorithms.

\textbf{source}: https://gym.openai.com/docs/

    \hypertarget{learn-by-doing-a-reinforcement-learning-experiment-using-openai-gym}{%
\subsection{Learn by doing -- A reinforcement learning experiment using
OpenAI
Gym}\label{learn-by-doing-a-reinforcement-learning-experiment-using-openai-gym}}

    \hypertarget{creating-a-gym-environment}{%
\subsubsection{Creating a Gym
environment}\label{creating-a-gym-environment}}

To start using OpenAI Gym, one must install it and import it into a
Python environment. One can either use a pre-made environment for
testing, or build their own.

For this experiment, I will be using the pre-built `CartPole'
environment. The state consists of the cart's position and velocity, and
the pole's angle and velocity. The actions are applying a force of +1 or
-1 to the cart. The goal is to keep the pole balanced for 500 game
steps. The reward is 1 on each step for as long as the pole is balanced.

We can view the action and observation space as follows.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{2}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{gym}

\PY{n}{env} \PY{o}{=} \PY{n}{gym}\PY{o}{.}\PY{n}{make}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{CartPole\PYZhy{}v1}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{observation} \PY{o}{=} \PY{n}{env}\PY{o}{.}\PY{n}{reset}\PY{p}{(}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{n}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Action Space Shape: }\PY{l+s+si}{\PYZob{}env.action\PYZus{}space\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Action Example: }\PY{l+s+s2}{\PYZob{}}\PY{l+s+s2}{env.action\PYZus{}space.sample()\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{n}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Observation Space Shape: }\PY{l+s+si}{\PYZob{}env.observation\PYZus{}space\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Observation Example: }\PY{l+s+si}{\PYZob{}observation\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Action Space Shape: Discrete(2)
Action Example: 1
Observation Space Shape: Box(4,)
Observation Example: [ 0.0132411   0.0352145  -0.028805   -0.01244701]
\end{Verbatim}

    We can also render the environment, until an episode completes, as
follows.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{3}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Enables recording}
\PY{c+c1}{\PYZsh{} import gym}
\PY{c+c1}{\PYZsh{} from gym.wrappers import Monitor}
\PY{c+c1}{\PYZsh{} env = gym.make(\PYZdq{}Acrobot\PYZhy{}v1\PYZdq{})}
\PY{c+c1}{\PYZsh{} env = Monitor(env, \PYZsq{}./video\PYZsq{})}

\PY{n}{env}\PY{o}{.}\PY{n}{reset}\PY{p}{(}\PY{p}{)}
\PY{n}{done} \PY{o}{=} \PY{k+kc}{False}

\PY{k}{while} \PY{o+ow}{not} \PY{n}{done}\PY{p}{:}
  \PY{n}{env}\PY{o}{.}\PY{n}{render}\PY{p}{(}\PY{p}{)}
  \PY{n}{action} \PY{o}{=} \PY{n}{env}\PY{o}{.}\PY{n}{action\PYZus{}space}\PY{o}{.}\PY{n}{sample}\PY{p}{(}\PY{p}{)}
  \PY{n}{observation}\PY{p}{,} \PY{n}{reward}\PY{p}{,} \PY{n}{done}\PY{p}{,} \PY{n}{info} \PY{o}{=} \PY{n}{env}\PY{o}{.}\PY{n}{step}\PY{p}{(}\PY{n}{action}\PY{p}{)}

\PY{n}{env}\PY{o}{.}\PY{n}{close}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    In the prior code block, we take random actions and only utilize the
\texttt{done} information to determine if a session has finished. You
can either run the code to see the animation for youself, or view the
video below.

    \hypertarget{building-a-smarter-agent-with-reinforcement-learning-and-tabular-methods}{%
\subsection{Building a smarter agent with reinforcement learning and
tabular
methods}\label{building-a-smarter-agent-with-reinforcement-learning-and-tabular-methods}}

Tabular methods use arrays and tables to hold an approximate of the
value functions. More simply, they store every combination of
state/action pairs and hold a perceived value of that pair. This
simplifies the learning process because tables are very quick to compute
and can give decent results given the state and action spaces are small
enough. One can also reduce the size of the state and action spaces to
make the agent learn evey quicker due to a smaller table to fill (at the
cost of a reduced accuracy). One idea that can be implemented, that I
will not use in the Acrobot example, is to transform state values before
binning them. For example, one could use a sigmoid function to spread
the state values out so that the center distrubtion gets put into more
bins while the outliers get grouped together.

To apply a tabular method to this CartPole example, we simply need a
table that holds every possible state/action pair. Due to the size of
this table, I bin the state values into 20 buckets so that there are 2 *
4\^{}20 values to compute. I also add a randomness factor to force my
agent to explore more in the beginning then slowly exploit more as it
learns. Feel free to edit the global variables (hyperparameters) to see
what happens. This tabular method is also very random in how well it
does with a small amount of sessions.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{1}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Configuration Values and Imports}

\PY{k+kn}{import} \PY{n+nn}{gym}

\PY{n}{env} \PY{o}{=} \PY{n}{gym}\PY{o}{.}\PY{n}{make}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{CartPole\PYZhy{}v1}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
\PY{k+kn}{import} \PY{n+nn}{math}
\PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
\PY{k+kn}{import} \PY{n+nn}{random}

\PY{n}{RENDER\PYZus{}STEPS} \PY{o}{=} \PY{l+m+mi}{250}
\PY{n}{SESSIONS} \PY{o}{=} \PY{l+m+mi}{500}

\PY{n}{BINS} \PY{o}{=} \PY{l+m+mi}{20}
\PY{n}{REWARD\PYZus{}DISCOUNT} \PY{o}{=} \PY{l+m+mf}{0.98}
\PY{n}{LEARNING\PYZus{}RATE\PYZus{}DECAY} \PY{o}{=} \PY{l+m+mf}{0.995}
\PY{n}{LEARNING\PYZus{}RATE\PYZus{}MIN} \PY{o}{=} \PY{l+m+mf}{0.150}
\PY{n}{EXPLORATION\PYZus{}RATE} \PY{o}{=} \PY{l+m+mf}{1.0}
\PY{n}{EXPLORATION\PYZus{}RATE\PYZus{}DECAY} \PY{o}{=} \PY{l+m+mf}{0.975}
\PY{n}{EXPLORTATION\PYZus{}RATE\PYZus{}MIN} \PY{o}{=} \PY{l+m+mf}{0.005}

\PY{n}{BUFFER\PYZus{}SIZE} \PY{o}{=} \PY{l+m+mi}{20}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{2}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Include a plotting class to show results :]}

\PY{k}{class} \PY{n+nc}{Plotter}\PY{p}{:}
    \PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{)}\PY{p}{:}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}x\PYZus{}values} \PY{o}{=} \PY{p}{[}\PY{p}{]}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}y\PYZus{}values} \PY{o}{=} \PY{p}{[}\PY{p}{]}

    \PY{k}{def} \PY{n+nf}{add\PYZus{}plot\PYZus{}pair}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{x}\PY{p}{,} \PY{n}{y}\PY{p}{)}\PY{p}{:}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}x\PYZus{}values}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{x}\PY{p}{)}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}y\PYZus{}values}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{y}\PY{p}{)}

    \PY{k}{def} \PY{n+nf}{plot}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{)}\PY{p}{:}
        \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}x\PYZus{}values}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}y\PYZus{}values}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}

    \PY{k}{def} \PY{n+nf}{plot\PYZus{}and\PYZus{}save}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{file\PYZus{}name}\PY{p}{)}\PY{p}{:}
        \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}x\PYZus{}values}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}y\PYZus{}values}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{savefig}\PY{p}{(}\PY{n}{file\PYZus{}name}\PY{p}{)}

    \PY{k}{def} \PY{n+nf}{plot\PYZus{}smooth\PYZus{}graph}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{averaging\PYZus{}filter\PYZus{}length}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{)}\PY{p}{:}
        \PY{k}{if} \PY{n}{averaging\PYZus{}filter\PYZus{}length} \PY{o}{\PYZgt{}} \PY{n+nb}{len}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}x\PYZus{}values}\PY{p}{)}\PY{p}{:}
            \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{p}{)}
            \PY{k}{return}

        \PY{n}{rolling\PYZus{}average} \PY{o}{=} \PY{p}{[}\PY{p}{]}
        \PY{k}{for} \PY{n}{index} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}x\PYZus{}values}\PY{p}{)}\PY{p}{)}\PY{p}{:}
            \PY{n}{min\PYZus{}index} \PY{o}{=} \PY{n}{index} \PY{o}{\PYZhy{}} \PY{p}{(}\PY{n}{averaging\PYZus{}filter\PYZus{}length} \PY{o}{/} \PY{l+m+mi}{2}\PY{p}{)}
            \PY{n}{min\PYZus{}index} \PY{o}{=} \PY{n+nb}{int}\PY{p}{(}\PY{l+m+mi}{0} \PY{k}{if} \PY{n}{min\PYZus{}index} \PY{o}{\PYZlt{}} \PY{l+m+mi}{0} \PY{k}{else} \PY{n}{min\PYZus{}index}\PY{p}{)}
            \PY{n}{max\PYZus{}index} \PY{o}{=} \PY{n}{index} \PY{o}{+} \PY{p}{(}\PY{n}{averaging\PYZus{}filter\PYZus{}length} \PY{o}{/} \PY{l+m+mi}{2}\PY{p}{)}
            \PY{n}{max\PYZus{}index} \PY{o}{=} \PY{n+nb}{int}\PY{p}{(}
                \PY{n+nb}{len}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}x\PYZus{}values}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}
                \PY{k}{if} \PY{n}{max\PYZus{}index} \PY{o}{\PYZgt{}}\PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}x\PYZus{}values}\PY{p}{)}
                \PY{k}{else} \PY{n}{max\PYZus{}index}
            \PY{p}{)}

            \PY{n}{rolling\PYZus{}average}\PY{o}{.}\PY{n}{append}\PY{p}{(}
                \PY{n+nb}{sum}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}y\PYZus{}values}\PY{p}{[}\PY{n}{min\PYZus{}index}\PY{p}{:}\PY{n}{max\PYZus{}index}\PY{p}{]}\PY{p}{)} \PY{o}{/}\PY{o}{/} \PY{p}{(}\PY{n}{max\PYZus{}index} \PY{o}{\PYZhy{}} \PY{n}{min\PYZus{}index}\PY{p}{)}
            \PY{p}{)}

        \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Steps Achieved Per Session Over Training Duration}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Sessions}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Steps Achieved Per Session}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}
            \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}x\PYZus{}values}\PY{p}{,}
            \PY{n}{rolling\PYZus{}average}\PY{p}{,}
            \PY{n}{color}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZsh{}ade6bb}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
            \PY{n}{linewidth}\PY{o}{=}\PY{l+m+mf}{2.5}\PY{p}{,}
            \PY{n}{label}\PY{o}{=}\PY{n}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Running Average of }\PY{l+s+si}{\PYZob{}averaging\PYZus{}filter\PYZus{}length\PYZcb{}}\PY{l+s+s2}{ Sessions}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
        \PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}
            \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}x\PYZus{}values}\PY{p}{,}
            \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}y\PYZus{}values}\PY{p}{,}
            \PY{n}{color}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZsh{}e6add8}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
            \PY{n}{linewidth}\PY{o}{=}\PY{l+m+mf}{0.25}\PY{p}{,}
            \PY{n}{label}\PY{o}{=}\PY{n}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Raw Steps Achieved}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
        \PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{3}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Some selective replay experience}

\PY{k}{class} \PY{n+nc}{ReplayExperience}\PY{p}{:}
    \PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{buffer\PYZus{}size}\PY{p}{)}\PY{p}{:}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}buffer} \PY{o}{=} \PY{p}{[}\PY{p}{]}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}buffer\PYZus{}size} \PY{o}{=} \PY{n}{buffer\PYZus{}size}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}forgetfullness} \PY{o}{=} \PY{l+m+mf}{0.15}

    \PY{k}{def} \PY{n+nf}{get\PYZus{}experience}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{)}\PY{p}{:}
        \PY{k}{return} \PY{n}{random}\PY{o}{.}\PY{n}{choice}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}buffer}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}

    \PY{k}{def} \PY{n+nf}{make\PYZus{}experience}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{value}\PY{p}{,} \PY{n}{experience}\PY{p}{)}\PY{p}{:}
        \PY{k}{if} \PY{n+nb}{len}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}buffer}\PY{p}{)} \PY{o}{\PYZlt{}} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}buffer\PYZus{}size}\PY{p}{:}
            \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}buffer}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{(}\PY{n}{value}\PY{p}{,} \PY{n}{experience}\PY{p}{)}\PY{p}{)}
            \PY{k}{return}

        \PY{k}{if} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{rand}\PY{p}{(}\PY{p}{)} \PY{o}{\PYZlt{}}\PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}forgetfullness}\PY{p}{:}
            \PY{k}{del} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}buffer}\PY{p}{[}\PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{randint}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}buffer}\PY{p}{)}\PY{p}{)}\PY{p}{]}

        \PY{c+c1}{\PYZsh{} Find the worst memory and replace it}
        \PY{n}{min\PYZus{}value} \PY{o}{=} \PY{n}{value}
        \PY{n}{min\PYZus{}index} \PY{o}{=} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}
        \PY{k}{for} \PY{n}{index} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}buffer}\PY{p}{)}\PY{p}{)}\PY{p}{:}
            \PY{k}{if} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}buffer}\PY{p}{[}\PY{n}{index}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{\PYZlt{}} \PY{n}{min\PYZus{}value}\PY{p}{:}
                \PY{n}{min\PYZus{}value} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}buffer}\PY{p}{[}\PY{n}{index}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
                \PY{n}{min\PYZus{}index} \PY{o}{=} \PY{n}{index}
        \PY{k}{if} \PY{n}{min\PYZus{}index} \PY{o}{!=} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{:}
            \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}buffer}\PY{p}{[}\PY{n}{min\PYZus{}index}\PY{p}{]} \PY{o}{=} \PY{p}{(}\PY{n}{value}\PY{p}{,} \PY{n}{experience}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{4}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Main table class that includes data normalization using sigmoids}

\PY{k}{class} \PY{n+nc}{Table}\PY{p}{:}
    \PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}
        \PY{n+nb+bp}{self}\PY{p}{,}
        \PY{n}{action\PYZus{}space}\PY{p}{,}
        \PY{n}{observation\PYZus{}space}\PY{p}{,}
        \PY{n}{bins}\PY{p}{,}
        \PY{n}{reward\PYZus{}dicount}\PY{p}{,}
        \PY{n}{exploration\PYZus{}rate}\PY{p}{,}
        \PY{n}{exploration\PYZus{}rate\PYZus{}min}\PY{p}{,}
        \PY{n}{exploration\PYZus{}rate\PYZus{}decay}\PY{p}{,}
        \PY{n}{learning\PYZus{}rate\PYZus{}min}\PY{p}{,}
        \PY{n}{learning\PYZus{}rate\PYZus{}decay}\PY{p}{,}
    \PY{p}{)}\PY{p}{:}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}action\PYZus{}space} \PY{o}{=} \PY{n}{action\PYZus{}space}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}observation\PYZus{}space} \PY{o}{=} \PY{n}{observation\PYZus{}space}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}bins} \PY{o}{=} \PY{n}{bins}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}reward\PYZus{}discount} \PY{o}{=} \PY{n}{reward\PYZus{}dicount}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}exploration\PYZus{}rate} \PY{o}{=} \PY{n}{exploration\PYZus{}rate}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}exploration\PYZus{}rate\PYZus{}min} \PY{o}{=} \PY{n}{exploration\PYZus{}rate\PYZus{}min}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}exploration\PYZus{}rate\PYZus{}decay} \PY{o}{=} \PY{n}{exploration\PYZus{}rate\PYZus{}decay}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}learning\PYZus{}rates} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{ones}\PY{p}{(}
            \PY{p}{(}\PY{n}{bins} \PY{o}{*}\PY{o}{*} \PY{n}{observation\PYZus{}space}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{action\PYZus{}space}\PY{o}{.}\PY{n}{n}\PY{p}{)}
        \PY{p}{)}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}learning\PYZus{}rate\PYZus{}min} \PY{o}{=} \PY{n}{learning\PYZus{}rate\PYZus{}min}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}learning\PYZus{}rate\PYZus{}decay} \PY{o}{=} \PY{n}{learning\PYZus{}rate\PYZus{}decay}

        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}table} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{(}\PY{n}{bins} \PY{o}{*}\PY{o}{*} \PY{n}{observation\PYZus{}space}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{action\PYZus{}space}\PY{o}{.}\PY{n}{n}\PY{p}{)}\PY{p}{)}

    \PY{k}{def} \PY{n+nf}{act}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{observation}\PY{p}{)}\PY{p}{:}
        \PY{n}{observation} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}scale\PYZus{}observation}\PY{p}{(}\PY{n}{observation}\PY{p}{)}
        \PY{n+nb}{bin} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}bin\PYZus{}observation}\PY{p}{(}\PY{n}{observation}\PY{p}{)}

        \PY{k}{if} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{rand}\PY{p}{(}\PY{p}{)} \PY{o}{\PYZlt{}}\PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}exploration\PYZus{}rate}\PY{p}{:}
            \PY{k}{return} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}action\PYZus{}space}\PY{o}{.}\PY{n}{sample}\PY{p}{(}\PY{p}{)}

        \PY{k}{return} \PY{n}{np}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}table}\PY{p}{[}\PY{n+nb}{bin}\PY{p}{]}\PY{p}{)}

    \PY{k}{def} \PY{n+nf}{learn\PYZus{}from\PYZus{}experience}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{experience}\PY{p}{)}\PY{p}{:}
        \PY{n}{penalty} \PY{o}{=} \PY{o}{\PYZhy{}}\PY{n+nb}{sum}\PY{p}{(}\PY{n}{step}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]} \PY{k}{for} \PY{n}{step} \PY{o+ow}{in} \PY{n}{experience}\PY{p}{)}
        \PY{n}{experience\PYZus{}length} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{experience}\PY{p}{)}
        \PY{n}{discount} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}reward\PYZus{}discount}

        \PY{k}{for} \PY{n}{index} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{experience\PYZus{}length} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{:}
            \PY{n}{observation}\PY{p}{,} \PY{n}{action}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{experience}\PY{p}{[}\PY{n}{index}\PY{p}{]}
            \PY{n}{observation} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}scale\PYZus{}observation}\PY{p}{(}\PY{n}{observation}\PY{p}{)}
            \PY{n+nb}{bin} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}bin\PYZus{}observation}\PY{p}{(}\PY{n}{observation}\PY{p}{)}

            \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}table}\PY{p}{[}\PY{n+nb}{bin}\PY{p}{]}\PY{p}{[}\PY{n}{action}\PY{p}{]} \PY{o}{+}\PY{o}{=} \PY{p}{(}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}learning\PYZus{}rates}\PY{p}{[}\PY{n+nb}{bin}\PY{p}{]}\PY{p}{[}\PY{n}{action}\PY{p}{]} \PY{o}{*} \PY{n}{discount} \PY{o}{*} \PY{n}{penalty}
            \PY{p}{)}

            \PY{n}{discount} \PY{o}{*}\PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}reward\PYZus{}discount}
            \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}update\PYZus{}learning\PYZus{}rate}\PY{p}{(}\PY{n+nb}{bin}\PY{p}{,} \PY{n}{action}\PY{p}{)}

        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}update\PYZus{}exploration\PYZus{}rate}\PY{p}{(}\PY{p}{)}

    \PY{k}{def} \PY{n+nf}{\PYZus{}update\PYZus{}learning\PYZus{}rate}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n+nb}{bin}\PY{p}{,} \PY{n}{action}\PY{p}{)}\PY{p}{:}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}learning\PYZus{}rates}\PY{p}{[}\PY{n+nb}{bin}\PY{p}{]}\PY{p}{[}\PY{n}{action}\PY{p}{]} \PY{o}{*}\PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}learning\PYZus{}rate\PYZus{}decay}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}learning\PYZus{}rates}\PY{p}{[}\PY{n+nb}{bin}\PY{p}{]}\PY{p}{[}\PY{n}{action}\PY{p}{]} \PY{o}{=} \PY{n+nb}{max}\PY{p}{(}
            \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}learning\PYZus{}rate\PYZus{}min}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}learning\PYZus{}rates}\PY{p}{[}\PY{n+nb}{bin}\PY{p}{]}\PY{p}{[}\PY{n}{action}\PY{p}{]}
        \PY{p}{)}

    \PY{k}{def} \PY{n+nf}{\PYZus{}update\PYZus{}exploration\PYZus{}rate}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{)}\PY{p}{:}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}exploration\PYZus{}rate} \PY{o}{*}\PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}exploration\PYZus{}rate\PYZus{}decay}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}exploration\PYZus{}rate} \PY{o}{=} \PY{n+nb}{max}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}exploration\PYZus{}rate\PYZus{}min}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}exploration\PYZus{}rate}\PY{p}{)}

    \PY{k}{def} \PY{n+nf}{\PYZus{}sigmoid}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{x}\PY{p}{)}\PY{p}{:}
        \PY{k}{return} \PY{l+m+mi}{1} \PY{o}{/} \PY{p}{(}\PY{l+m+mi}{1} \PY{o}{+} \PY{n}{np}\PY{o}{.}\PY{n}{exp}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{n}{x}\PY{p}{)}\PY{p}{)}

    \PY{k}{def} \PY{n+nf}{\PYZus{}scale\PYZus{}observation}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{observation}\PY{p}{)}\PY{p}{:}
        \PY{n}{scaled\PYZus{}observation} \PY{o}{=} \PY{p}{[}\PY{p}{]}

        \PY{k}{for} \PY{n}{index} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}observation\PYZus{}space}\PY{o}{.}\PY{n}{low}\PY{p}{)}\PY{p}{)}\PY{p}{:}
            \PY{n}{high} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}sigmoid}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}observation\PYZus{}space}\PY{o}{.}\PY{n}{high}\PY{p}{[}\PY{n}{index}\PY{p}{]}\PY{p}{)}
            \PY{n}{low} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}sigmoid}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}observation\PYZus{}space}\PY{o}{.}\PY{n}{low}\PY{p}{[}\PY{n}{index}\PY{p}{]}\PY{p}{)}

            \PY{n}{scaled\PYZus{}value} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}sigmoid}\PY{p}{(}\PY{n}{observation}\PY{p}{[}\PY{n}{index}\PY{p}{]}\PY{p}{)}
            \PY{n}{scaled\PYZus{}value} \PY{o}{=} \PY{p}{(}\PY{n}{scaled\PYZus{}value} \PY{o}{\PYZhy{}} \PY{n}{low}\PY{p}{)} \PY{o}{/} \PY{p}{(}\PY{n}{high} \PY{o}{\PYZhy{}} \PY{n}{low}\PY{p}{)}
            \PY{n}{normalized\PYZus{}value} \PY{o}{=} \PY{n}{scaled\PYZus{}value} \PY{o}{*} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{\PYZus{}bins}

            \PY{n}{scaled\PYZus{}observation}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n+nb}{int}\PY{p}{(}\PY{n}{normalized\PYZus{}value}\PY{p}{)}\PY{p}{)}

        \PY{k}{return} \PY{n}{scaled\PYZus{}observation}

    \PY{k}{def} \PY{n+nf}{\PYZus{}bin\PYZus{}observation}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{observation}\PY{p}{)}\PY{p}{:}
        \PY{n+nb}{bin} \PY{o}{=} \PY{l+m+mi}{0}
        \PY{k}{for} \PY{n}{index} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{observation}\PY{p}{)}\PY{p}{)}\PY{p}{:}
            \PY{n+nb}{bin} \PY{o}{+}\PY{o}{=} \PY{p}{(}\PY{l+m+mi}{2} \PY{o}{*}\PY{o}{*} \PY{n}{index}\PY{p}{)} \PY{o}{*} \PY{n}{observation}\PY{p}{[}\PY{n}{index}\PY{p}{]}
        \PY{k}{return} \PY{n+nb}{int}\PY{p}{(}\PY{n+nb}{bin}\PY{p}{)}  \PY{c+c1}{\PYZsh{} must be an int since it is used as an index}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{5}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Creating objects before training starts}

\PY{n}{plotter} \PY{o}{=} \PY{n}{Plotter}\PY{p}{(}\PY{p}{)}
\PY{n}{replay\PYZus{}experience} \PY{o}{=} \PY{n}{ReplayExperience}\PY{p}{(}\PY{n}{BUFFER\PYZus{}SIZE}\PY{p}{)}
\PY{n}{table} \PY{o}{=} \PY{n}{Table}\PY{p}{(}
    \PY{n}{env}\PY{o}{.}\PY{n}{action\PYZus{}space}\PY{p}{,}
    \PY{n}{env}\PY{o}{.}\PY{n}{observation\PYZus{}space}\PY{p}{,}
    \PY{n}{BINS}\PY{p}{,}
    \PY{n}{REWARD\PYZus{}DISCOUNT}\PY{p}{,}
    \PY{n}{EXPLORATION\PYZus{}RATE}\PY{p}{,}
    \PY{n}{EXPLORTATION\PYZus{}RATE\PYZus{}MIN}\PY{p}{,}
    \PY{n}{EXPLORATION\PYZus{}RATE\PYZus{}DECAY}\PY{p}{,}
    \PY{n}{LEARNING\PYZus{}RATE\PYZus{}MIN}\PY{p}{,}
    \PY{n}{LEARNING\PYZus{}RATE\PYZus{}DECAY}\PY{p}{,}
\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{6}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Training}

\PY{k}{for} \PY{n}{session} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{SESSIONS} \PY{o}{+} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{:}  \PY{c+c1}{\PYZsh{} offset by 1 for better formatting in results}
    \PY{n}{done} \PY{o}{=} \PY{k+kc}{False}
    \PY{n}{step} \PY{o}{=} \PY{l+m+mi}{0}
    \PY{n}{experience} \PY{o}{=} \PY{p}{[}\PY{p}{]}

    \PY{n}{observation} \PY{o}{=} \PY{n}{env}\PY{o}{.}\PY{n}{reset}\PY{p}{(}\PY{p}{)}

    \PY{k}{while} \PY{o+ow}{not} \PY{n}{done}\PY{p}{:}

        \PY{k}{if} \PY{n}{session} \PY{o}{\PYZpc{}} \PY{n}{RENDER\PYZus{}STEPS} \PY{o}{==} \PY{l+m+mi}{1}\PY{p}{:}
            \PY{n}{env}\PY{o}{.}\PY{n}{render}\PY{p}{(}\PY{p}{)}
        \PY{n}{step} \PY{o}{+}\PY{o}{=} \PY{l+m+mi}{1}

        \PY{n}{action} \PY{o}{=} \PY{n}{table}\PY{o}{.}\PY{n}{act}\PY{p}{(}\PY{n}{observation}\PY{p}{)}
        \PY{n}{observation}\PY{p}{,} \PY{n}{reward}\PY{p}{,} \PY{n}{done}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{env}\PY{o}{.}\PY{n}{step}\PY{p}{(}\PY{n}{action}\PY{p}{)}

        \PY{n}{experience}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{(}\PY{n}{observation}\PY{p}{,} \PY{n}{action}\PY{p}{,} \PY{n}{reward}\PY{p}{)}\PY{p}{)}

    \PY{n}{table}\PY{o}{.}\PY{n}{learn\PYZus{}from\PYZus{}experience}\PY{p}{(}\PY{n}{experience}\PY{p}{)}
    \PY{n}{replay\PYZus{}experience}\PY{o}{.}\PY{n}{make\PYZus{}experience}\PY{p}{(}\PY{n}{step}\PY{p}{,} \PY{n}{experience}\PY{p}{)}
    \PY{n}{experience} \PY{o}{=} \PY{n}{replay\PYZus{}experience}\PY{o}{.}\PY{n}{get\PYZus{}experience}\PY{p}{(}\PY{p}{)}
    \PY{n}{table}\PY{o}{.}\PY{n}{learn\PYZus{}from\PYZus{}experience}\PY{p}{(}\PY{n}{experience}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} print(f\PYZdq{}Session \PYZob{}session\PYZcb{} took \PYZob{}step\PYZcb{} steps.\PYZdq{})  \PYZhy{}\PYZhy{} prints too much in Jupyter}
    \PY{n}{plotter}\PY{o}{.}\PY{n}{add\PYZus{}plot\PYZus{}pair}\PY{p}{(}\PY{n}{session}\PY{p}{,} \PY{n}{step}\PY{p}{)}

\PY{n}{env}\PY{o}{.}\PY{n}{close}\PY{p}{(}\PY{p}{)}
\PY{n}{plotter}\PY{o}{.}\PY{n}{plot\PYZus{}smooth\PYZus{}graph}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
c:\textbackslash{}program files\textbackslash{}python37\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}ipykernel\_launcher.py:70:
RuntimeWarning: overflow encountered in exp
\end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{Index_files/Index_15_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Once again, if you do not wish to run the code, some results are shown
below. Unfortunatly, the graph does not show the legend; the green line
shows a running average of 100 sessions while the light pink line shows
the actual values at each session.


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
